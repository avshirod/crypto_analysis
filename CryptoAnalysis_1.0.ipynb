{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Created on:   03/03/2018  Aditya Shirode\n",
    "# Modified on:  03/08/2018  Aditya Shirode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO DO:\n",
    "- Make generic functions for tasks for modularity\n",
    "- CRON jobs for all timeframes\n",
    "- One function to update all csvs\n",
    "- Plug n play for indicators\n",
    "- Add limit to queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import time\n",
    "import talib\n",
    "import logging\n",
    "import requests\n",
    "import datetime\n",
    "import importlib\n",
    "import dateutil.parser\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(logging)\n",
    "LOGGING_FORMAT = '%(asctime)s - %(levelname)s - %(message)s'\n",
    "logging.basicConfig(format=LOGGING_FORMAT, level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cryptocompare_wrapper = os.path.join(os.curdir, 'cryptocompare_wrapper.py')\n",
    "import cryptocompare_wrapper as ccw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIELDS\n",
    "PRICE = 'PRICE'\n",
    "HIGH = 'HIGH24HOUR'\n",
    "LOW = 'LOW24HOUR'\n",
    "VOLUME = 'VOLUME24HOUR'\n",
    "CHANGE = 'CHANGE24HOUR'\n",
    "CHANGE_PERCENT = 'CHANGEPCT24HOUR'\n",
    "MARKETCAP = 'MKTCAP'\n",
    "NPERIODS = 100\n",
    "TIMEFRAME = 'Day'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defaults\n",
    "CURR = 'BTC'\n",
    "EXCHANGE = 'CCCAGG'\n",
    "COIN = 'ETH'\n",
    "COIN_LIST = ['BTC', 'ETH', 'XRP']\n",
    "EXCHANGES = ['Kucoin', 'Cryptopia', 'HitBTC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coin DB\n",
    "coins = ccw.get_coin_list()\n",
    "COIN_DB = pd.DataFrame.from_dict(coins, orient='index')\n",
    "# COIN_DB.to_csv('coin_list.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exchange DB\n",
    "exchanges = ccw.get_exchanges_list()\n",
    "EXCHANGE_DB = pd.DataFrame.from_dict(exchanges, orient='index')\n",
    "# EXCHANGE_DB.to_csv('exchanges_list.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:21: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n",
      "ERROR:root:'NoneType' object has no attribute 'empty'\n",
      "ERROR:root:'NoneType' object has no attribute 'empty'\n",
      "ERROR:root:Did not update the following. Try again.\n",
      " defaultdict(<class 'list'>, {'Cryptopia': ['XRP'], 'Kucoin': ['XRP']})\n"
     ]
    }
   ],
   "source": [
    "# Update historical data (per day) for all coins\n",
    "\n",
    "csv_all_coins_day_full = 'all_coins_day_full.csv'\n",
    "not_updated = defaultdict(list)\n",
    "existing_coin_exchange = []\n",
    "to_curr = 'BTC'\n",
    "\n",
    "# If the csv already exists, find out which coins and exchanges have already been added\n",
    "if os.path.isfile(csv_all_coins_day_full):\n",
    "    df_csv_all_coins_day_full = pd.read_csv(csv_all_coins_day_full)\n",
    "    # existing_coin_exchange is a list of tuples (coin, exchange)\n",
    "    existing_coin_exchange = pd.MultiIndex.from_product((df_csv_all_coins_day_full['coin'].unique(),\n",
    "                                                         df_csv_all_coins_day_full['exchange'].unique())).get_values()\n",
    "\n",
    "\n",
    "for exchange in EXCHANGES :\n",
    "    # for symbol in COIN_DB.Symbol:\n",
    "    for symbol in COIN_LIST:\n",
    "    # for symbol in EXCHANGE_DB.loc[exchange].dropna().index:\n",
    "        # If the tuple does not exist in the csv\n",
    "        if (symbol, exchange) not in existing_coin_exchange:\n",
    "            try:\n",
    "                # Can't fetch the same symbol in same symbol rate\n",
    "                if symbol is not to_curr:\n",
    "                    df_coin_day_all = ccw.get_historical_price_day_full(\n",
    "                        coin=symbol,\n",
    "                        to_curr=to_curr,\n",
    "                        timestamp=time.time(),\n",
    "                        exchange=exchange\n",
    "                    )\n",
    "                    if df_coin_day_all.empty:\n",
    "                        not_updated[exchange].append(symbol)\n",
    "                    else:\n",
    "                        df_coin_day_all['exchange'] = exchange\n",
    "                        df_coin_day_all['coin'] = symbol\n",
    "\n",
    "                        # If csv does not exist, write, else append\n",
    "                        if not os.path.isfile(csv_all_coins_day_full):\n",
    "                            df_coin_day_all.to_csv(csv_all_coins_day_full, mode='w')\n",
    "                        else:\n",
    "                            df_coin_day_all.to_csv(csv_all_coins_day_full, mode='a', header=False)\n",
    "            except Exception as e:\n",
    "                logging.error(e)\n",
    "                # logging.debug(\"Could not update data for {curr} from {exchange}\".format(curr=symbol, exchange=exchange))\n",
    "                not_updated[exchange].append(symbol)\n",
    "\n",
    "logging.error(\"Did not update the following. Try again.\\n {not_updated}\".format(not_updated=not_updated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maps csv (future data objects) to period granularity\n",
    "# If we store all data together in a single data source, we'll change this to a function which returns corresponding rows\n",
    "data_csv_period_mapping = {\n",
    "    \"day\": 'all_coins_day_full.csv',\n",
    "    \"hour\": 'all_coins_hour_full.csv',\n",
    "    \"min\": 'all_coins_min_full.csv'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_data_csv(coin_symbol=['BTC'], nrows=1, period='day'):\n",
    "    \"\"\" Fetch data from csv for mentioned coins \n",
    "        This function fetches last nrows from csv corr to given period\n",
    "    \"\"\"\n",
    "    period = period.lower()\n",
    "    csv_filename = data_csv_period_mapping[period]\n",
    "    df_csv = pd.read_csv(csv_filename, index_col=None)\n",
    "    # print(coin_symbol)\n",
    "    return_df = []\n",
    "    for coin in coin_symbol:\n",
    "        # Get rows where 'coin' is one of the coin_symbols; then extract last nrows\n",
    "        req_data = df_csv[df_csv['coin'] == coin].iloc[-nrows:]\n",
    "        if req_data.empty:\n",
    "            continue\n",
    "        req_columns = ['coin', 'time', 'open', 'high', 'low', 'close', 'volumeto']\n",
    "        req_data = req_data[req_columns]\n",
    "        return_df.append(req_data)\n",
    "    return return_df\n",
    "    # return pd.concat(return_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_day_10 = fetch_data_csv(list(COIN_DB.Symbol), nrows=10, period=TIMEFRAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import talib.abstract as taa\n",
    "inp_data_coin1 = df_day_10[0]\n",
    "inp_data_coin2 = df_day_10[1]\n",
    "inp_sma = taa.SMA(inp_data_coin1, timeperiod=3)\n",
    "inp_sma_two = taa.SMA(inp_data_coin2, timeperiod=5)\n",
    "inp_rsi = talib.RSI(inp_data_coin1.close.values, timeperiod=14)\n",
    "inp_mfi = talib.MFI(inp_data_coin1.high.values, inp_data_coin1.low.values, inp_data_coin1.close.values, inp_data_coin1.volumeto.values, timeperiod=14)\n",
    "inp_bbands = talib.BBANDS(inp_data_coin1.close.values, timeperiod=20, nbdevup=2, nbdevdn=2, matype=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_indicator(csv_filename, indicator_data, indicator):\n",
    "    \"\"\" Update the given csv_file with new column values for corr rows \"\"\"\n",
    "    df_csv = pd.read_csv(csv_filename, index_col=None)\n",
    "    if indicator not in df_csv.columns:\n",
    "        df_csv[indicator] = np.nan\n",
    "    df_csv = df_csv.set_index(['coin', 'time'])\n",
    "    indicator_data = indicator_data.set_index(['coin', 'time'])\n",
    "    df_csv.update(indicator_data)\n",
    "    df_csv.to_csv(csv_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_last_day(coin):\n",
    "    \"\"\" Get data for last day \"\"\"\n",
    "    df_coin_last_day = ccw.get_historical_price_last_day(COIN)\n",
    "    df_coin_last_day['coin'] = coin\n",
    "    last_entry = df_coin_last_day.iloc[-1:]\n",
    "    return last_entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_last_day(coin):\n",
    "    \"\"\" Update csv for last day \"\"\"\n",
    "    record_last_day = fetch_last_day(COIN)\n",
    "    csv_day = 'coin_day_full.csv'\n",
    "    df_day = pd.read_csv(csv_day)\n",
    "    record = df_day[df_day['timestamp'] == record_last_day.iloc[0]['timestamp']]\n",
    "    if record.empty:\n",
    "        record_last_day.to_csv(csv_day, mode='a', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_period_mapping = {\n",
    "    'day': ccw.get_historical_price_day,\n",
    "    'hour': ccw.get_historical_price_hour,\n",
    "    'minute': ccw.get_historical_price_minute\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_data_api(coin=COIN, to_curr=CURR, nperiods=1, period='day'):\n",
    "    \"\"\" Fetch data for coin over nperiods\n",
    "        e.g. Get data for 'BTC' for past 12 hours in hours granularity\n",
    "    \"\"\"\n",
    "    period = period.lower()\n",
    "    func = function_period_mapping[period]\n",
    "    coin_last_nperiods = func(\n",
    "        coin=coin,\n",
    "        to_curr=to_curr,\n",
    "        limit=nperiods\n",
    "    )\n",
    "    return coin_last_nperiods.iloc[-int(nperiods):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_csv_to_latest(period='day'):\n",
    "    \"\"\" Update the csv for given period upto current time for coin \"\"\"\n",
    "    period = period.lower()\n",
    "    csv_filename = data_csv_period_mapping[period]  # Get corr csv\n",
    "    df_coin_period = pd.read_csv(csv_filename)  # , index_col=['coin', 'exchange']\n",
    "    csv_column_order = df_coin_period.columns.tolist()\n",
    "    df_coin_period = df_coin_period.set_index(keys=['coin', 'exchange'])\n",
    "    \n",
    "    lst_new_data = []\n",
    "    PRINT_MSG = \"{:15} {!s:20} {!s:>20} {:>10}\"\n",
    "    logging.info(PRINT_MSG.format(\"Exchange\", \"Last Updated Time\", \"Elapsed Time\", \"nPeriodsAgo\"))\n",
    "    coins_in_csv = list(df_coin_period.index.get_level_values(0).unique())\n",
    "    for coin in coins_in_csv:\n",
    "        df_coin_period_coin = df_coin_period.loc[coin]\n",
    "        # Group by exchange, sort on timestamp, and get the \n",
    "        last_update = df_coin_period_coin.groupby('exchange', group_keys=False).apply(lambda c: c.sort_values(by='time').tail(1))\n",
    "        logging.info(\"-\" * 10 + \" For coin - {}\".format(coin))\n",
    "        # print(last_update)\n",
    "        for exchange in last_update.index.values:\n",
    "            last_updated_time = last_update.loc[exchange]['time']\n",
    "            try:\n",
    "                elapsed_time = datetime.datetime.now() - datetime.datetime.strptime(last_updated_time, '%Y-%m-%d %H:%M:%S')\n",
    "            except ValueError as e:\n",
    "                logging.info(\"Failed to parse time {} for {}--{}\".format(last_updated_time, coin, exchange))\n",
    "                elapsed_time = datetime.datetime.now() - dateutil.parser.parse(last_updated_time)\n",
    "            nperiods_ago = elapsed_time / datetime.timedelta(days=1 if period == 'day' else 0,\n",
    "                                                             hours=1 if period == 'hour' else 0,\n",
    "                                                             minutes=1 if period == 'minute' else 0,\n",
    "                                                             seconds=1)\n",
    "            nperiods_ago = np.floor(nperiods_ago)\n",
    "            \n",
    "            logging.info(PRINT_MSG.format(exchange, last_updated_time, elapsed_time, nperiods_ago))\n",
    "            \n",
    "            if nperiods_ago > 0:\n",
    "                logging.info(\"Updating data for {coin}-{exchange} from {last_updated_time}\".format(\n",
    "                    coin=coin, exchange=exchange, last_updated_time=last_updated_time)\n",
    "                )\n",
    "                new_data_coin_period = fetch_data_api(\n",
    "                    coin=coin,\n",
    "                    nperiods=nperiods_ago,\n",
    "                    period=period\n",
    "                )\n",
    "                new_data_coin_period['coin'] = coin\n",
    "                new_data_coin_period['exchange'] = exchange\n",
    "                lst_new_data.append(new_data_coin_period)\n",
    "    \n",
    "    if lst_new_data:\n",
    "        df_new_data = pd.concat(lst_new_data)\n",
    "        curr_columns = df_new_data.columns.tolist()\n",
    "        column_order = [col for col in csv_column_order if col in curr_columns]\n",
    "        df_new_data = df_new_data.reindex(columns=column_order)\n",
    "        df_new_data.to_csv(csv_filename, mode='a', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-08 06:53:58,775 - INFO - Exchange        Last Updated Time            Elapsed Time nPeriodsAgo\n",
      "2018-03-08 06:53:58,787 - INFO - ---------- For coin - ETH\n",
      "2018-03-08 06:53:58,789 - INFO - Cryptopia       2018-03-07 16:00:00       14:53:58.789656        0.0\n",
      "2018-03-08 06:53:58,790 - INFO - HitBTC          2018-03-07 16:00:00       14:53:58.790655        0.0\n",
      "2018-03-08 06:53:58,792 - INFO - Kucoin          2018-03-07 16:00:00       14:53:58.792662        0.0\n",
      "2018-03-08 06:53:58,801 - INFO - ---------- For coin - XRP\n",
      "2018-03-08 06:53:58,802 - INFO - Failed to parse time 2018-03-06 16:00 for XRP--HitBTC\n",
      "2018-03-08 06:53:58,804 - INFO - HitBTC          2018-03-06 16:00     1 day, 14:53:58.804693        1.0\n",
      "2018-03-08 06:53:58,805 - INFO - Updating data for XRP-HitBTC from 2018-03-06 16:00\n"
     ]
    }
   ],
   "source": [
    "update_csv_to_latest()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
